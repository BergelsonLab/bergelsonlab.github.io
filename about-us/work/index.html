<html><head><title>What We&apos;re Working On</title></head><body><table width="100%"><tr valign="top"><td width="150px"><table><tr><th align="left">Navigation</th></tr><tr><td><small><a href="../../about-us/index.html">About Us</a></small></td></tr><tr><td><small><a href="../../contact-us/index.html">Contact Us</a></small></td></tr><tr><td><small><a href="../../events/index.html">Events</a></small></td></tr><tr><td><small><a href="../../home/index.html">Home</a></small></td></tr><tr><td><small><a href="../../media/index.html">Media</a></small></td></tr><tr><td><small><a href="../../methods/index.html">Methods &amp; Documentation</a></small></td></tr><tr><td><small><a href="../../news/index.html">News</a></small></td></tr><tr><td><small><a href="../../publications/index.html">Publications</a></small></td></tr></table></td><td>&#160;</td><td><div class="hentry webpage" id="https://sites.google.com/feeds/content/site/bergelsonlabduke/645310978299539945"><div><a href="../index.html">About Us</a> &gt; </div><h3><span class="entry-title">What We&apos;re Working On</span></h3><div><div class="entry-content"><div xmlns='http://www.w3.org/1999/xhtml'><table class='sites-layout-name-one-column sites-layout-hbox' cellspacing='0'><tbody><tr><td class='sites-layout-tile sites-tile-name-content-1'><div dir='ltr'><div><br/><div class='sites-embed-align-center-wrapping-off'><div style='width:450px;' class='sites-embed-border-on sites-embed'><div class='sites-embed-content sites-embed-type-text'><div class='sites-embed-content-textbox'><html xmlns:jot='http://www.google.com/ns/jotspot/srvtmpl/'><div dir='ltr'><h2 style='text-align:left'><font size='4'>SEEDLings</font></h2><div style='text-align:left'><span style='font-size:medium'><br/></span></div><div style='text-align:left'><span style='font-size:medium'>Before moving to Duke, the Bergelson lab was at the University of Rochester. Here we conducted a longitudinal data collection project known as SEEDLings (Study of Environmental Effects on Developing LINGuistic Skills). We followed 44 babies from 6-18 months and tracked their linguistic environment with audio and video recordings. Every month we obtained an hour long video recording and a 16 hour audio recording of an average day in the life of our babies. Babies were brought in for eye tracking every other month to measure what words they had learned. You can find more information about this project </span><a rel='nofollow' style='font-size:medium' target='_blank' href='http://www.bcs.rochester.edu/seedlings/'>here</a><span style='font-size:medium'>.</span></div></div></html></div></div></div></div><div class='sites-embed-align-center-wrapping-off'><div style='width:450px;' class='sites-embed-border-on sites-embed'><div class='sites-embed-content sites-embed-type-text'><div class='sites-embed-content-textbox'><html xmlns:jot='http://www.google.com/ns/jotspot/srvtmpl/'><div dir='ltr'><h2><font size='4' face='arial, sans-serif' color='#000000'>Catherine Laing</font></h2><div><font face='Calibri, Arial, Helvetica, sans-serif' color='#000000'><span style='font-size:16px'><br/></span></font></div><span style='color:rgb(0,0,0);font-family:Calibri,Arial,Helvetica,sans-serif;font-size:16px'>I've recently finished working on my PhD thesis, where I studied infants' acquisition of onomatopoeia from perspectives of production, perception and early interactions. </span><span style='color:rgb(0,0,0);font-family:Calibri,Arial,Helvetica,sans-serif;font-size:16px'>I'm currently analyzing infants' transition from babble to words, focusing on how caregiver speech shapes infants' early production. </span><span style='color:rgb(0,0,0);font-family:Calibri,Arial,Helvetica,sans-serif;font-size:16px'> I plan to start extending my analysis to eye-tracking data, to see if infants attend more to words and objects when they are congruent with their babble production.</span></div></html></div></div></div></div><div><div><div class='sites-embed-align-center-wrapping-off'><div style='width:450px;' class='sites-embed-border-on sites-embed'><div class='sites-embed-content sites-embed-type-text'><div class='sites-embed-content-textbox'><html xmlns:jot='http://www.google.com/ns/jotspot/srvtmpl/'><div dir='ltr'><h2><font size='4'>Charlotte Moore</font></h2><div><span style='color:rgb(0,0,0);font-family:Calibri,Arial,Helvetica,sans-serif;font-size:16px'>Charlotte is interested in looking at if 14-month-olds try to predict what words they're hearing before they've heard the entire word. </span><font style='color:rgb(0,0,0)' size='2' face='Calibri,Arial,Helvetica,sans-serif,Apple Color Emoji,Segoe UI Emoji,NotoColorEmoji,Segoe UI Symbol,Android Emoji,EmojiSymbols'><span style='font-size:16px'>As a person speaks, their mouth starts getting ready to make the next sound in the word before finishing the previous sound. This is called coarticulation. Coarticulation creates cues in words that hint at what's coming next. </span></font><span style='color:rgb(0,0,0);font-family:Calibri,Arial,Helvetica,sans-serif;font-size:16px'>Research shows that older children and adults use coarticulation cues in the speech stream to try and make guesses about what sounds are coming up as they listen to speech. Charlotte is designing an eye-tracking study to determine whether or not babies at this age are already showing this skill. If 14-month-olds, who are only saying a few words and don't have a lot of practice producing speech, show the same pattern as older children, we can conclude that it's not necessary to have practice speaking to know how coarticulation cues work.</span></div></div></html></div></div></div></div><div><div class='sites-embed-align-center-wrapping-off'><div style='width:450px;' class='sites-embed-border-on sites-embed'><div class='sites-embed-content sites-embed-type-text'><div class='sites-embed-content-textbox'><html xmlns:jot='http://www.google.com/ns/jotspot/srvtmpl/'><div dir='ltr'><h2><font size='4'>Shannon Dailey</font></h2><div><font size='3'>TBD...</font></div></div></html></div></div></div></div></div></div><div class='sites-embed-align-center-wrapping-off'><div style='width:450px;' class='sites-embed-border-on sites-embed'><div class='sites-embed-content sites-embed-type-text'><div class='sites-embed-content-textbox'><html xmlns:jot='http://www.google.com/ns/jotspot/srvtmpl/'><div dir='ltr'><h2><font size='4'>Andrei Amatuni</font></h2><div><font size='3'>I recently finished the initial development work on a project called <a rel='nofollow' href='https://github.com/SeedlingsBabylab/idslabel'>IDSLabel</a>. This is a client/server application for distributing large audio datasets to human coders to classify as either adult or infant directed speech. These human gold standard classifications will be used to train machine learning systems. I'm currently interested in vector space models of semantics, and hope to use the SEEDLings corpus to explore these ideas. </font></div></div></html></div></div></div></div></div></div><br/></div></td></tr></tbody></table></div></div><br /><small>Updated on <abbr class="updated" title="2016-11-30T16:59:30.103Z">Nov 30, 2016</abbr> by <span class="author"><span class="vcard"><a class="fn" href="mailto:seedlingsur@gmail.com">Seedlings University of Rochester</a></span></span> (Version <span class="sites:revision">32</span>)</small><br /><br /></div></div></td></tr></table></body></html>